{
  "_duxport_model_version": "2.0",
  "format": "pkl",
  "model_info": {
    "model_id": "gradient_boost_reg",
    "model_name": "Gradient Boosting Regressor",
    "task_type": "regression",
    "target_column": "actual_price",
    "features": [
      "location",
      "area_sqft",
      "bhk",
      "bathrooms",
      "floor",
      "total_floors",
      "age_of_property",
      "parking",
      "lift"
    ],
    "metrics": {
      "r2_score": 0.8564156817288764,
      "mse": 9815045801276.594,
      "rmse": 3132897.3493040903,
      "mae": 2318745.232096418
    },
    "feature_importance": [
      {
        "name": "area_sqft",
        "importance": 0.6161749064983638
      },
      {
        "name": "age_of_property",
        "importance": 0.09531643625192011
      },
      {
        "name": "bhk",
        "importance": 0.08912897381954185
      },
      {
        "name": "floor",
        "importance": 0.07608064516129034
      },
      {
        "name": "total_floors",
        "importance": 0.05208110432111135
      },
      {
        "name": "location",
        "importance": 0.03794527649769587
      },
      {
        "name": "bathrooms",
        "importance": 0.024522657450076812
      },
      {
        "name": "lift",
        "importance": 0.008125000000000002
      },
      {
        "name": "parking",
        "importance": 0.0006250000000000002
      }
    ],
    "training_time_ms": 16286
  },
  "configuration": {
    "epochs": 25,
    "learning_rate": 0.01,
    "batch_size": 32,
    "test_split": 20
  },
  "dataset_info": {
    "rows": 2500,
    "columns": 10,
    "file_name": "navi_mumbai_real_estate_uncleaned_2500_cleaned.csv"
  },
  "all_model_results": [
    {
      "model_id": "gradient_boost_reg",
      "model_name": "Gradient Boosting Regressor",
      "metrics": {
        "r2_score": 0.8564156817288764,
        "mse": 9815045801276.594,
        "rmse": 3132897.3493040903,
        "mae": 2318745.232096418
      },
      "feature_importance": [
        {
          "name": "area_sqft",
          "importance": 0.6161749064983638
        },
        {
          "name": "age_of_property",
          "importance": 0.09531643625192011
        },
        {
          "name": "bhk",
          "importance": 0.08912897381954185
        },
        {
          "name": "floor",
          "importance": 0.07608064516129034
        },
        {
          "name": "total_floors",
          "importance": 0.05208110432111135
        },
        {
          "name": "location",
          "importance": 0.03794527649769587
        },
        {
          "name": "bathrooms",
          "importance": 0.024522657450076812
        },
        {
          "name": "lift",
          "importance": 0.008125000000000002
        },
        {
          "name": "parking",
          "importance": 0.0006250000000000002
        }
      ],
      "training_time_ms": 16286
    },
    {
      "model_id": "random_forest_reg",
      "model_name": "Random Forest Regressor",
      "metrics": {
        "r2_score": 0.5433024551833704,
        "mse": 31218641239370.445,
        "rmse": 5587364.426934263,
        "mae": 4156991.502390785
      },
      "feature_importance": [
        {
          "name": "area_sqft",
          "importance": 0.308555222673741
        },
        {
          "name": "age_of_property",
          "importance": 0.13897710067848387
        },
        {
          "name": "floor",
          "importance": 0.12098093784475913
        },
        {
          "name": "total_floors",
          "importance": 0.11872966921062947
        },
        {
          "name": "location",
          "importance": 0.09825972504300162
        },
        {
          "name": "bathrooms",
          "importance": 0.08156135352797184
        },
        {
          "name": "bhk",
          "importance": 0.06470935567418123
        },
        {
          "name": "lift",
          "importance": 0.036876948937096296
        },
        {
          "name": "parking",
          "importance": 0.031349686410135566
        }
      ],
      "training_time_ms": 9626
    },
    {
      "model_id": "neural_net_reg",
      "model_name": "Neural Network (MLP)",
      "metrics": {
        "r2_score": 0.829080935018803,
        "mse": 11683577087674.197,
        "rmse": 3418124.791120739,
        "mae": 2676710.660696782
      },
      "feature_importance": [
        {
          "name": "area_sqft",
          "importance": 0.308555222673741
        },
        {
          "name": "age_of_property",
          "importance": 0.13897710067848387
        },
        {
          "name": "floor",
          "importance": 0.12098093784475913
        },
        {
          "name": "total_floors",
          "importance": 0.11872966921062947
        },
        {
          "name": "location",
          "importance": 0.09825972504300162
        },
        {
          "name": "bathrooms",
          "importance": 0.08156135352797184
        },
        {
          "name": "bhk",
          "importance": 0.06470935567418123
        },
        {
          "name": "lift",
          "importance": 0.036876948937096296
        },
        {
          "name": "parking",
          "importance": 0.031349686410135566
        }
      ],
      "training_time_ms": 18788
    }
  ],
  "python_reconstruction_script": "\"\"\"\nAuto-generated by Duxport ML Dashboard\nReconstructs the trained model in scikit-learn and saves as .pkl / .joblib\n\nUsage:\n  pip install scikit-learn pandas numpy joblib\n  python load_model.py\n\"\"\"\n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport joblib\nimport pickle\n\n# ── Configuration ──\nTASK_TYPE = \"regression\"\nTARGET_COLUMN = \"actual_price\"\nFEATURES = [\"location\",\"area_sqft\",\"bhk\",\"bathrooms\",\"floor\",\"total_floors\",\"age_of_property\",\"parking\",\"lift\"]\nBEST_MODEL = \"gradient_boost_reg\"\nTEST_SPLIT = 0.2\n\n# Best model metrics from browser training:\n# r2_score: 0.8564, mse: 9815045801276.5938, rmse: 3132897.3493, mae: 2318745.2321\n\nprint(f\"Setting up {BEST_MODEL} for {TASK_TYPE} task...\")\nprint(f\"Target: {TARGET_COLUMN}, Features: {len(FEATURES)}\")\n\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\n\nMODELS = {\n    \"linear_regression\": LinearRegression(),\n    \"ridge_regression\": Ridge(alpha=1.0),\n    \"decision_tree_reg\": DecisionTreeRegressor(max_depth=10, random_state=42),\n    \"random_forest_reg\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"gradient_boost_reg\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n    \"knn_reg\": KNeighborsRegressor(n_neighbors=5),\n    \"svr\": SVR(),\n    \"neural_net_reg\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=25, random_state=42),\n}\n\n# Load your CSV:\ndf = pd.read_csv(\"navi_mumbai_real_estate_uncleaned_2500_cleaned.csv\")\nX = df[FEATURES]\ny = df[TARGET_COLUMN]\n\n# Encode categoricals\nfor col in X.select_dtypes(include=['object']).columns:\n    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n\n\n# Scale features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=42)\n\n# Train the best model\nmodel = MODELS.get(BEST_MODEL, list(MODELS.values())[0])\nprint(f\"\\nTraining {model.__class__.__name__}...\")\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test)\nprint(f\"Test Score: {score:.4f}\")\n\n# Save as .pkl\nwith open(\"model.pkl\", \"wb\") as f:\n    pickle.dump({\"model\": model, \"scaler\": scaler, \"features\": FEATURES, \"target\": TARGET_COLUMN}, f)\nprint(\"Saved: model.pkl\")\n\n# Save as .joblib\njoblib.dump({\"model\": model, \"scaler\": scaler, \"features\": FEATURES, \"target\": TARGET_COLUMN}, \"model.joblib\")\nprint(\"Saved: model.joblib\")\n\nprint(\"\\nDone! Load with: pickle.load(open('model.pkl','rb')) or joblib.load('model.joblib')\")\n",
  "exported_at": "2026-02-23T09:41:39.164Z",
  "_note": "This is a Duxport model package. Use the included python_reconstruction_script to reconstruct a scikit-learn model from your CSV data."
}